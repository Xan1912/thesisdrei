2021-10-03 09:16:14.511465: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2021-10-03 09:16:15.999393: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)
Epoch 1/10



14/14 [==============================] - 53s 618ms/step - loss: 0.7409 - accuracy: 0.4783 - val_loss: 0.6635 - val_accuracy: 0.7347
Epoch 2/10


14/14 [==============================] - 6s 412ms/step - loss: 0.6813 - accuracy: 0.6128 - val_loss: 0.6229 - val_accuracy: 0.5714
Epoch 3/10

14/14 [==============================] - 6s 407ms/step - loss: 0.5837 - accuracy: 0.7305 - val_loss: 0.6391 - val_accuracy: 0.6735
Epoch 4/10

14/14 [==============================] - 6s 423ms/step - loss: 0.4141 - accuracy: 0.8479 - val_loss: 0.7723 - val_accuracy: 0.6327
Epoch 5/10

14/14 [==============================] - 6s 432ms/step - loss: 0.3753 - accuracy: 0.8322 - val_loss: 0.5975 - val_accuracy: 0.6939
Epoch 6/10

14/14 [==============================] - 6s 435ms/step - loss: 0.1696 - accuracy: 0.9327 - val_loss: 0.7701 - val_accuracy: 0.7347
Epoch 7/10

14/14 [==============================] - 6s 408ms/step - loss: 0.1028 - accuracy: 0.9665 - val_loss: 0.9277 - val_accuracy: 0.7347
Epoch 8/10


14/14 [==============================] - 6s 432ms/step - loss: 0.0426 - accuracy: 0.9848 - val_loss: 1.4695 - val_accuracy: 0.7143
Epoch 9/10


14/14 [==============================] - 6s 412ms/step - loss: 0.0387 - accuracy: 0.9803 - val_loss: 1.2265 - val_accuracy: 0.6939
Epoch 10/10



14/14 [==============================] - 6s 413ms/step - loss: 0.0125 - accuracy: 0.9995 - val_loss: 1.2787 - val_accuracy: 0.6939
Result:
               precision    recall  f1-score   support
           0       0.49      0.43      0.46        99
           1       0.53      0.59      0.56       108
    accuracy                           0.52       207
   macro avg       0.51      0.51      0.51       207
weighted avg       0.51      0.52      0.51       207